{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IOHMM import IOHMM_model\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Financial-Data/stocks/TSLA.csv\")\n",
    "data.head()\n",
    "data = data.dropna()\n",
    "\n",
    "input = torch.tensor(np.array(data[['Open']]), dtype=torch.float32)\n",
    "output = torch.tensor(np.array(data['Close']), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a simple model manully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.5000, 0.5000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([5., 5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "transition_matrix = torch.tensor([[[1.,0.],[1.,0.]],[[1.,0.],[1.,0.]]])\n",
    "emission_matrix = torch.tensor([[-0.1,0.1],[0.1,0.1]])\n",
    "\n",
    "IOHMM = IOHMM_model(num_states=2, inputs=input[:100], outputs=output[:100], max_iter=1000, tol=1e-4, transition_matrix=transition_matrix, emission_matrix=emission_matrix)\n",
    "print(IOHMM.initial_pi)\n",
    "print(IOHMM.transition_matrix)\n",
    "print(IOHMM.emission_matrix)\n",
    "print(IOHMM.lsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(IOHMM._forward())\n",
    "# torch.sum(IOHMM._forward(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(IOHMM._backward())\n",
    "# torch.sum(IOHMM._backward(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(IOHMM._compute_gamma(IOHMM._forward(), IOHMM._backward()))\n",
    "# torch.sum(IOHMM._compute_gamma(IOHMM._forward(), IOHMM._backward()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]],\n",
      "\n",
      "        [[0.5000, 0.5000],\n",
      "         [0.5000, 0.5000]]])\n"
     ]
    }
   ],
   "source": [
    "print(IOHMM._compute_xi(IOHMM._forward(), IOHMM._backward()))\n",
    "# torch.sum(IOHMM._compute_xi(IOHMM._forward(), IOHMM._backward()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, likelihood: -inf\n",
      "Iteration 2, likelihood: -139.14013671875\n",
      "Iteration 3, likelihood: -139.0100860595703\n",
      "Iteration 4, likelihood: -138.90835571289062\n",
      "Iteration 5, likelihood: -138.82461547851562\n",
      "Iteration 6, likelihood: -138.75486755371094\n",
      "Iteration 7, likelihood: -138.99172973632812\n",
      "Iteration 8, likelihood: -193.3594970703125\n",
      "Iteration 9, likelihood: -3018.88134765625\n",
      "Iteration 10, likelihood: -599.308349609375\n",
      "Iteration 11, likelihood: 0.012427536770701408\n",
      "Iteration 12, likelihood: 0.05032605305314064\n",
      "Iteration 13, likelihood: 0.08550626784563065\n",
      "Iteration 14, likelihood: 0.11833508312702179\n",
      "Iteration 15, likelihood: 0.14910945296287537\n",
      "Iteration 16, likelihood: 0.17807315289974213\n",
      "Iteration 17, likelihood: 0.20542870461940765\n",
      "Iteration 18, likelihood: 0.2313467562198639\n",
      "Iteration 19, likelihood: 0.25597143173217773\n",
      "Iteration 20, likelihood: 0.2794264554977417\n",
      "Iteration 21, likelihood: 0.30181869864463806\n",
      "Iteration 22, likelihood: 0.3232404887676239\n",
      "Iteration 23, likelihood: 0.34377312660217285\n",
      "Iteration 24, likelihood: 0.36348778009414673\n",
      "Iteration 25, likelihood: 0.38244733214378357\n",
      "Iteration 26, likelihood: 0.4007079303264618\n",
      "Iteration 27, likelihood: 0.41831907629966736\n",
      "Iteration 28, likelihood: 0.43532612919807434\n",
      "Iteration 29, likelihood: 0.45176902413368225\n",
      "Iteration 30, likelihood: 0.4676840305328369\n",
      "Iteration 31, likelihood: 0.4831041991710663\n",
      "Iteration 32, likelihood: 0.4980594217777252\n",
      "Iteration 33, likelihood: 0.5125775933265686\n",
      "Iteration 34, likelihood: 0.5266831517219543\n",
      "Iteration 35, likelihood: 0.5403989553451538\n",
      "Iteration 36, likelihood: 0.5537459850311279\n",
      "Iteration 37, likelihood: 0.5667439103126526\n",
      "Iteration 38, likelihood: 0.5794102549552917\n",
      "Iteration 39, likelihood: 0.5917617678642273\n",
      "Iteration 40, likelihood: 0.603813648223877\n",
      "Iteration 41, likelihood: 0.6155802607536316\n",
      "Iteration 42, likelihood: 0.6270747184753418\n",
      "Iteration 43, likelihood: 0.6383092999458313\n",
      "Iteration 44, likelihood: 0.6492958068847656\n",
      "Iteration 45, likelihood: 0.6600446105003357\n",
      "Iteration 46, likelihood: 0.6705662608146667\n",
      "Iteration 47, likelihood: 0.6808699369430542\n",
      "Iteration 48, likelihood: 0.6909642815589905\n",
      "Iteration 49, likelihood: 0.7008580565452576\n",
      "Iteration 50, likelihood: 0.7105588316917419\n",
      "Iteration 51, likelihood: 0.7200740575790405\n",
      "Iteration 52, likelihood: 0.7294106483459473\n",
      "Iteration 53, likelihood: 0.7385755777359009\n",
      "Iteration 54, likelihood: 0.7475746273994446\n",
      "Iteration 55, likelihood: 0.7564139366149902\n",
      "Iteration 56, likelihood: 0.7650989294052124\n",
      "Iteration 57, likelihood: 0.7736351490020752\n",
      "Iteration 58, likelihood: 0.7820273041725159\n",
      "Iteration 59, likelihood: 0.7902803421020508\n",
      "Iteration 60, likelihood: 0.798399031162262\n",
      "Iteration 61, likelihood: 0.8063872456550598\n",
      "Iteration 62, likelihood: 0.8142495155334473\n",
      "Iteration 63, likelihood: 0.8219894766807556\n",
      "Iteration 64, likelihood: 0.8296111226081848\n",
      "Iteration 65, likelihood: 0.8371176719665527\n",
      "Iteration 66, likelihood: 0.8445130586624146\n",
      "Iteration 67, likelihood: 0.8518001437187195\n",
      "Iteration 68, likelihood: 0.8589820861816406\n",
      "Iteration 69, likelihood: 0.8660619258880615\n",
      "Iteration 70, likelihood: 0.8730428218841553\n",
      "Iteration 71, likelihood: 0.8799271583557129\n",
      "Iteration 72, likelihood: 0.8867176175117493\n",
      "Iteration 73, likelihood: 0.8934165239334106\n",
      "Iteration 74, likelihood: 0.900026798248291\n",
      "Iteration 75, likelihood: 0.9065505266189575\n",
      "Iteration 76, likelihood: 0.9129899740219116\n",
      "Iteration 77, likelihood: 0.9193474650382996\n",
      "Iteration 78, likelihood: 0.9256244897842407\n",
      "Iteration 79, likelihood: 0.9318236112594604\n",
      "Iteration 80, likelihood: 0.9379464387893677\n",
      "Iteration 81, likelihood: 0.9439949989318848\n",
      "Iteration 82, likelihood: 0.9499711990356445\n",
      "Iteration 83, likelihood: 0.9558769464492798\n",
      "Iteration 84, likelihood: 0.9617130160331726\n",
      "Iteration 85, likelihood: 0.967481791973114\n",
      "Iteration 86, likelihood: 0.9731847643852234\n",
      "Iteration 87, likelihood: 0.9788229465484619\n",
      "Iteration 88, likelihood: 0.984398365020752\n",
      "Iteration 89, likelihood: 0.9899119734764099\n",
      "Iteration 90, likelihood: 0.9953652620315552\n",
      "Iteration 91, likelihood: 1.000759482383728\n",
      "Iteration 92, likelihood: 1.0060960054397583\n",
      "Iteration 93, likelihood: 1.0113760232925415\n",
      "Iteration 94, likelihood: 1.0166007280349731\n",
      "Iteration 95, likelihood: 1.0217714309692383\n",
      "Iteration 96, likelihood: 1.0268888473510742\n",
      "Iteration 97, likelihood: 1.0319544076919556\n",
      "Iteration 98, likelihood: 1.03696870803833\n",
      "Iteration 99, likelihood: 1.041933536529541\n",
      "Iteration 100, likelihood: 1.0468493700027466\n",
      "Iteration 101, likelihood: 1.0517172813415527\n",
      "Iteration 102, likelihood: 1.0565378665924072\n",
      "Iteration 103, likelihood: 1.0613124370574951\n",
      "Iteration 104, likelihood: 1.0660419464111328\n",
      "Iteration 105, likelihood: 1.070726752281189\n",
      "Iteration 106, likelihood: 1.075368046760559\n",
      "Iteration 107, likelihood: 1.0799663066864014\n",
      "Iteration 108, likelihood: 1.0845229625701904\n",
      "Iteration 109, likelihood: 1.0890381336212158\n",
      "Iteration 110, likelihood: 1.093513011932373\n",
      "Iteration 111, likelihood: 1.0979478359222412\n",
      "Iteration 112, likelihood: 1.1023437976837158\n",
      "Iteration 113, likelihood: 1.106701374053955\n",
      "Iteration 114, likelihood: 1.1110211610794067\n",
      "Iteration 115, likelihood: 1.1153037548065186\n",
      "Iteration 116, likelihood: 1.1195498704910278\n",
      "Iteration 117, likelihood: 1.1237603425979614\n",
      "Iteration 118, likelihood: 1.1279356479644775\n",
      "Iteration 119, likelihood: 1.1320760250091553\n",
      "Iteration 120, likelihood: 1.1361823081970215\n",
      "Iteration 121, likelihood: 1.140255093574524\n",
      "Iteration 122, likelihood: 1.1442952156066895\n",
      "Iteration 123, likelihood: 1.148302435874939\n",
      "Iteration 124, likelihood: 1.1522778272628784\n",
      "Iteration 125, likelihood: 1.156221866607666\n",
      "Iteration 126, likelihood: 1.1601353883743286\n",
      "Iteration 127, likelihood: 1.164018154144287\n",
      "Iteration 128, likelihood: 1.1678709983825684\n",
      "Iteration 129, likelihood: 1.1716941595077515\n",
      "Iteration 130, likelihood: 1.1754884719848633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mIOHMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_baum_welch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PML_project/IOHMM_self/IOHMM/IOHMM.py:218\u001b[0m, in \u001b[0;36mIOHMM_model._baum_welch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, likelihood: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_log_likelihood\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 218\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/optim/sgd.py:66\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m---> 66\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     69\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/PML_project/IOHMM_self/IOHMM/IOHMM.py:214\u001b[0m, in \u001b[0;36mIOHMM_model._baum_welch.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    213\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_likelihood(gamma, xi)\n\u001b[0;32m--> 214\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IOHMM._baum_welch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28cf45280>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(IOHMM.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pi\n",
      "Parameter containing:\n",
      "tensor([4.7929, 5.0561], requires_grad=True)\n",
      "Transition matrix\n",
      "Parameter containing:\n",
      "tensor([[[-5.1586, -8.6887],\n",
      "         [ 7.1586,  8.6887]],\n",
      "\n",
      "        [[ 1.5936,  0.8244],\n",
      "         [ 0.4064, -0.8244]]], requires_grad=True)\n",
      "Emission matrix\n",
      "Parameter containing:\n",
      "tensor([[-0.1000,  0.9000],\n",
      "        [ 0.1000,  0.9000]], requires_grad=True)\n",
      "Sd\n",
      "Parameter containing:\n",
      "tensor([5., 5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial pi\")\n",
    "print(IOHMM.initial_pi) # to normalize\n",
    "print(\"Transition matrix\")\n",
    "print(IOHMM.transition_matrix)\n",
    "print(\"Emission matrix\")\n",
    "print(IOHMM.emission_matrix)\n",
    "print(\"Sd\")\n",
    "print(IOHMM.lsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#call the viterbi algorithm\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mIOHMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PML_project/IOHMM_self/IOHMM/IOHMM.py:245\u001b[0m, in \u001b[0;36mIOHMM_model.viterbi\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m path\u001b[38;5;241m.\u001b[39mappend(last_state\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 245\u001b[0m     transition_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     last_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39mlog(transition_prob) \u001b[38;5;241m+\u001b[39m alpha[i])\n\u001b[1;32m    247\u001b[0m     path\u001b[38;5;241m.\u001b[39mappend(last_state\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#call the viterbi algorithm\n",
    "IOHMM.viterbi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the next output given the next input\n",
    "IOHMM.predict(input[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3260)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
